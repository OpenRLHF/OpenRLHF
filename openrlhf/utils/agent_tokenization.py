"""
Strategic Tokenization Handler for Agentic RLHF.

This module provides an abstract interface for token concatenation,
allowing users to inject model-specific tokenization strategies
while maintaining turn-boundary integrity.

Reference: https://github.com/OpenRLHF/OpenRLHF/issues/1128
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from transformers import PreTrainedTokenizer
import logging

logger = logging.getLogger(__name__)


@dataclass
class TokenSequence:
    """Represents a token sequence with metadata."""
    tokens: List[int]
    source: str  # 'observation', 'action', 'feedback', etc.
    original_text: Optional[str] = None

    def __len__(self):
        return len(self.tokens)

    def __repr__(self):
        return f"TokenSequence(source={self.source}, len={len(self.tokens)})"


@dataclass
class ConcatenationReport:
    """Report on token concatenation validation."""
    total_tokens: int
    turn_boundary_indices: Dict[str, Tuple[int, int]]  # {source: (start, end)}
    token_offset_warnings: List[str]
    is_valid: bool

    def summary(self):
        return (
            f"ConcatenationReport(total={self.total_tokens}, "
            f"valid={self.is_valid}, warnings={len(self.token_offset_warnings)})"
        )


class AgentTokenHandler(ABC):
    """
    Abstract base class for managing token concatenation in agentic training.

    Users should subclass this to implement model-specific tokenization strategies
    rather than expecting the framework to handle all token quirks.

    This design allows:
    - Per-model customization (e.g., Llama vs Qwen vs Mistral)
    - Turn-boundary integrity validation
    - Token offset tracking for gradient computation
    """

    def __init__(self, tokenizer: PreTrainedTokenizer, verbose: bool = False):
        """
        Initialize handler.

        Args:
            tokenizer: HuggingFace tokenizer
            verbose: Enable logging
        """
        self.tokenizer = tokenizer
        self.verbose = verbose
        self._validate_tokenizer()

    def _validate_tokenizer(self):
        """Validate tokenizer has required attributes."""
        if not hasattr(self.tokenizer, "eos_token_id"):
            raise ValueError("Tokenizer must have 'eos_token_id' attribute")

    @abstractmethod
    def handle_action_tokens(
        self,
        action_tokens: List[int],
        action_text: str,
    ) -> TokenSequence:
        """
        Process action tokens ensuring EOS consistency.

        Args:
            action_tokens: Raw token IDs from model generation
            action_text: Original text generated by model

        Returns:
            Processed TokenSequence with validated EOS token

        Raises:
            ValueError: If tokens and text are misaligned
        """
        pass

    @abstractmethod
    def handle_feedback_tokens(
        self,
        feedback_text: str,
    ) -> TokenSequence:
        """
        Process environment feedback tokens with proper formatting.

        Args:
            feedback_text: Environment feedback text

        Returns:
            TokenSequence with proper newline/special token formatting
        """
        pass

    @abstractmethod
    def concatenate_sequences(
        self,
        sequences: List[TokenSequence],
    ) -> Tuple[List[int], ConcatenationReport]:
        """
        Concatenate token sequences with boundary validation.

        Args:
            sequences: List of TokenSequence objects to concatenate

        Returns:
            Tuple of (concatenated_tokens, validation_report)

        Raises:
            ValueError: If concatenation violates turn-boundary integrity
        """
        pass


class DefaultAgentTokenHandler(AgentTokenHandler):
    """
    Default implementation addressing GitHub issue #1128.

    Provides sensible defaults for most open-source models
    while remaining model-agnostic enough for users to extend.
    """

    def __init__(
        self,
        tokenizer: PreTrainedTokenizer,
        verbose: bool = False,
        add_newline_before_feedback: bool = True,
    ):
        super().__init__(tokenizer, verbose)
        self.add_newline_before_feedback = add_newline_before_feedback

    def handle_action_tokens(
        self,
        action_tokens: List[int],
        action_text: str,
    ) -> TokenSequence:
        """
        Ensure action tokens end with EOS.

        Issue #1128: vLLM may not include EOS in generated tokens.
        This method validates and appends if missing.
        """
        if not action_tokens:
            return TokenSequence([], "action", action_text)

        action_tokens_copy = action_tokens.copy()

        # Validate EOS presence
        if action_tokens_copy[-1] != self.tokenizer.eos_token_id:
            action_tokens_copy.append(self.tokenizer.eos_token_id)
            if self.verbose:
                logger.info(
                    "[AgentTokenHandler] Appended EOS token (ID: %s) "
                    "to action sequence. New length: %s",
                    self.tokenizer.eos_token_id,
                    len(action_tokens_copy),
                )

        return TokenSequence(action_tokens_copy, "action", action_text)

    def handle_feedback_tokens(
        self,
        feedback_text: str,
    ) -> TokenSequence:
        """
        Format feedback with newline prefix.

        Issue #1128: Environment feedback needs explicit turn boundary marker
        to prevent self-attention from treating it as action continuation.
        """
        if self.add_newline_before_feedback and not feedback_text.startswith("\n"):
            formatted_text = "\n" + feedback_text
        else:
            formatted_text = feedback_text

        # Tokenize formatted text
        feedback_tokens = self.tokenizer(
            formatted_text,
            add_special_tokens=False,
            return_tensors="pt",
        )["input_ids"][0].tolist()

        return TokenSequence(feedback_tokens, "feedback", formatted_text)

    def concatenate_sequences(
        self,
        sequences: List[TokenSequence],
    ) -> Tuple[List[int], ConcatenationReport]:
        """
        Concatenate sequences with turn-boundary validation.

        Ensures that token offsets align with the model's attention mechanism
        expectations for multi-turn sequences.

        Defensive measures:
        - Zero-inference filtering: None entries and TokenSequence instances
          with empty tokens are removed before processing to avoid TypeError
          or IndexError. Dropped count is reported in token_offset_warnings.
        - State collision guard: If a duplicate seq.source is encountered,
          a warning is appended to the report (the later occurrence overwrites
          the boundary entry).
        - Mathematical precision: current_offset is set from len(concatenated)
          after each extend so that offsets stay strictly aligned with the
          actual concatenated list length.
        """
        concatenated: List[int] = []
        turn_boundaries: Dict[str, Tuple[int, int]] = {}
        warnings: List[str] = []

        # Zero-inference filtering: drop None and empty-token sequences
        filtered_sequences: List[TokenSequence] = [
            s
            for s in sequences
            if s is not None
            and isinstance(s, TokenSequence)
            and len(s.tokens) > 0
        ]
        dropped_count: int = len(sequences) - len(filtered_sequences)
        if dropped_count > 0:
            warnings.append(
                "Filtered out %s sequence(s) with None or empty tokens."
                % dropped_count
            )
            if self.verbose:
                logger.warning(
                    "[AgentTokenHandler] Dropped %s sequence(s) (None or empty).",
                    dropped_count,
                )

        current_offset: int = 0

        for seq in filtered_sequences:
            start_idx: int = current_offset
            concatenated.extend(seq.tokens)
            end_idx: int = len(concatenated)
            current_offset = end_idx

            # State collision guard: detect duplicate source key
            if seq.source in turn_boundaries:
                collision_msg = (
                    "Duplicate source key '%s' in turn boundaries; "
                    "later occurrence overwrites previous."
                ) % seq.source
                warnings.append(collision_msg)
                if self.verbose:
                    logger.warning("[AgentTokenHandler] %s", collision_msg)

            turn_boundaries[seq.source] = (start_idx, end_idx)

            if self.verbose:
                logger.debug(
                    "[AgentTokenHandler] Concatenated %s "
                    "(indices %s:%s, len=%s)",
                    seq.source,
                    start_idx,
                    end_idx,
                    len(seq.tokens),
                )

        # Validate concatenation integrity
        total_expected: int = sum(len(s.tokens) for s in filtered_sequences)
        if len(concatenated) != total_expected:
            warnings.append(
                "Token count mismatch: expected %s, got %s. "
                "This may indicate tokenizer re-encoding during concatenation."
                % (total_expected, len(concatenated))
            )

        report: ConcatenationReport = ConcatenationReport(
            total_tokens=len(concatenated),
            turn_boundary_indices=turn_boundaries,
            token_offset_warnings=warnings,
            is_valid=len(warnings) == 0,
        )

        return concatenated, report


class CustomAgentTokenHandlerExample(DefaultAgentTokenHandler):
    """
    Example of a custom tokenization strategy for a specific model.

    Users should subclass DefaultAgentTokenHandler or AgentTokenHandler
    and override methods for model-specific behavior.
    """

    def handle_action_tokens(
        self, action_tokens: List[int], action_text: str
    ) -> TokenSequence:
        # Your custom logic here
        return super().handle_action_tokens(action_tokens, action_text)

    def handle_feedback_tokens(self, feedback_text: str) -> TokenSequence:
        # Your custom logic here
        return super().handle_feedback_tokens(feedback_text)

    def concatenate_sequences(
        self, sequences: List[TokenSequence]
    ) -> Tuple[List[int], ConcatenationReport]:
        # Your custom logic here
        return super().concatenate_sequences(sequences)
